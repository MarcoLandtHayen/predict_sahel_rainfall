{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d771a8a",
   "metadata": {},
   "source": [
    "### Develop preprocessing pipeline\n",
    "\n",
    "The complete preprocessing pipeline is then put into a separate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc554624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech preamble:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from predict_sahel_rainfall.preprocessing import (\n",
    "    load_data,\n",
    "    split_sequence,\n",
    "    train_val_test_split,\n",
    "    scale_norm_inputs,\n",
    "    prepare_inputs_and_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aec7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set url to csv file containing CICMoD indices from desired release:\n",
    "data_url = (\n",
    "    \"https://github.com/MarcoLandtHayen/climate_index_collection/\"\n",
    "    \"releases/download/v2023.03.29.1/climate_indices.csv\"\n",
    ")\n",
    "\n",
    "# Choose ESM ('CESM' or 'FOCI'):\n",
    "ESM = 'CESM'\n",
    "\n",
    "# Select target index:\n",
    "target_index = 'PREC_SAHEL'\n",
    "\n",
    "# Select input features:\n",
    "input_features = [\n",
    "    'AMO', 'ENSO_12', 'ENSO_3', 'ENSO_34', 'ENSO_4', 'NAO_PC', 'NAO_ST', \n",
    "    'NP', 'PDO_PC', 'PREC_SAHEL', 'SAM_PC', 'SAM_ZM', 'SAT_N_ALL', 'SAT_N_LAND',\n",
    "    'SAT_N_OCEAN', 'SAT_S_ALL', 'SAT_S_LAND', 'SAT_S_OCEAN', 'SOI',\n",
    "    'SSS_ENA', 'SSS_NA', 'SSS_SA', 'SSS_WNA', 'SST_ESIO', 'SST_HMDR',\n",
    "    'SST_MED', 'SST_TNA', 'SST_TSA', 'SST_WSIO'\n",
    "]\n",
    "\n",
    "# Choose, whether to add months as one-hot encoded features:\n",
    "add_months = True\n",
    "\n",
    "# Choose, whether to normalize target index:\n",
    "norm_target = True\n",
    "\n",
    "# Set lead time for target index:\n",
    "lead_time = 1\n",
    "\n",
    "# Specify input length:\n",
    "input_length = 24\n",
    "\n",
    "# Specify amount of combined training and validation data relative to test data:\n",
    "train_test_split = 0.9\n",
    "\n",
    "# Specify relative amount of combined training and validation used for training:\n",
    "train_val_split = 0.8\n",
    "\n",
    "## Optionally choose to scale or normalize input features according to statistics from training data:\n",
    "# 'no': Keep raw input features.\n",
    "# 'scale_01': Scale input features with min/max scaling to [0,1].\n",
    "# 'scale_11': Scale input features with min/max scaling to [-1,1].\n",
    "# 'norm': Normalize input features, hence subtract mean and divide by std dev.\n",
    "scale_norm = 'scale_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce2eef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs and target:\n",
    "(\n",
    "    train_input,\n",
    "    train_target,\n",
    "    val_input,\n",
    "    val_target,\n",
    "    test_input,\n",
    "    test_target,\n",
    "    train_mean,\n",
    "    train_std,\n",
    "    train_min,\n",
    "    train_max,\n",
    ") = prepare_inputs_and_target(    \n",
    "    data_url=data_url,\n",
    "    ESM=ESM,\n",
    "    target_index=target_index,\n",
    "    input_features=input_features,\n",
    "    add_months=add_months,\n",
    "    norm_target=norm_target,\n",
    "    lead_time=lead_time,\n",
    "    input_length=input_length,\n",
    "    train_test_split=train_test_split,\n",
    "    train_val_split=train_val_split,\n",
    "    scale_norm=scale_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d390dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input shape (samples, time steps, features):  (8630, 1, 41)\n",
      "val_input shape (samples, time steps, features):  (2158, 1, 41)\n",
      "test_input shape (samples, time steps, features):  (1199, 1, 41)\n",
      "\n",
      "train_target shape (samples, 1):  (8630, 1)\n",
      "val_target shape (samples, 1):  (2158, 1)\n",
      "test_target shape (samples, 1):  (1199, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions:\n",
    "print(\"train_input shape (samples, time steps, features): \", train_input.shape)\n",
    "print(\"val_input shape (samples, time steps, features): \", val_input.shape)\n",
    "print(\"test_input shape (samples, time steps, features): \", test_input.shape)\n",
    "\n",
    "print(\"\\ntrain_target shape (samples, 1): \", train_target.shape)\n",
    "print(\"val_target shape (samples, 1): \", val_target.shape)\n",
    "print(\"test_target shape (samples, 1): \", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035f433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input MIN:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_input MAX:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "train_input MEAN:  [0.46 0.4  0.43 0.49 0.58 0.41 0.39 0.48 0.56 0.37 0.59 0.61 0.5  0.49\n",
      " 0.57 0.52 0.42 0.58 0.66 0.49 0.52 0.48 0.52 0.42 0.48 0.51 0.51 0.46\n",
      " 0.45 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08]\n",
      "train_input STD:  [0.13 0.14 0.16 0.17 0.18 0.12 0.12 0.12 0.15 0.08 0.12 0.13 0.12 0.11\n",
      " 0.11 0.11 0.12 0.11 0.11 0.15 0.15 0.16 0.16 0.14 0.11 0.11 0.11 0.12\n",
      " 0.14 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28]\n",
      "val_input MIN:  [-0.03  0.    0.02 -0.01 -0.01  0.08  0.04 -0.06  0.11  0.03  0.04  0.05\n",
      "  0.05  0.12  0.14  0.05  0.03  0.08  0.06 -0.08 -0.14 -0.03 -0.15 -0.09\n",
      "  0.13  0.09  0.15  0.09 -0.01  0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.  ]\n",
      "val_input MAX:  [0.81 0.9  0.97 0.98 0.96 0.98 0.91 1.   0.94 0.81 0.88 0.96 0.94 0.96\n",
      " 0.92 0.95 0.84 1.02 0.94 0.76 0.77 0.79 0.74 0.86 0.89 1.08 0.9  0.85\n",
      " 0.96 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.  ]\n",
      "val_input MEAN:  [0.42 0.4  0.43 0.48 0.57 0.42 0.39 0.48 0.55 0.37 0.59 0.61 0.49 0.48\n",
      " 0.56 0.52 0.41 0.57 0.66 0.34 0.37 0.37 0.39 0.41 0.47 0.5  0.51 0.48\n",
      " 0.46 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08]\n",
      "val_input STD:  [0.12 0.14 0.17 0.18 0.19 0.12 0.12 0.12 0.15 0.09 0.11 0.13 0.12 0.11\n",
      " 0.11 0.11 0.12 0.12 0.12 0.13 0.13 0.13 0.14 0.13 0.12 0.12 0.12 0.12\n",
      " 0.13 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28]\n",
      "test_input MIN:  [-0.04  0.01  0.    0.05  0.06  0.09  0.06  0.05  0.09  0.07  0.05  0.06\n",
      "  0.12  0.11  0.15  0.   -0.11  0.09  0.15  0.04  0.08 -0.09  0.03  0.01\n",
      "  0.19  0.14  0.19  0.13  0.04  0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.  ]\n",
      "test_input MAX:  [0.76 0.98 0.99 0.98 0.95 0.93 0.93 0.89 0.91 0.9  0.94 0.96 0.96 0.98\n",
      " 0.95 0.97 0.92 1.   0.98 0.63 0.67 0.8  0.8  0.86 0.84 0.97 0.87 0.95\n",
      " 0.94 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.  ]\n",
      "test_input MEAN:  [0.41 0.4  0.43 0.48 0.56 0.41 0.39 0.48 0.54 0.37 0.59 0.61 0.49 0.48\n",
      " 0.57 0.52 0.42 0.57 0.66 0.32 0.36 0.34 0.43 0.42 0.46 0.51 0.5  0.47\n",
      " 0.47 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08]\n",
      "test_input STD:  [0.12 0.15 0.18 0.18 0.18 0.12 0.12 0.11 0.14 0.09 0.12 0.14 0.12 0.11\n",
      " 0.11 0.11 0.12 0.12 0.12 0.11 0.11 0.15 0.14 0.14 0.11 0.11 0.12 0.14\n",
      " 0.13 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28]\n"
     ]
    }
   ],
   "source": [
    "# Check statistics:\n",
    "print(\"train_input MIN: \", np.round(np.min(train_input, axis=(0,1)), 2))\n",
    "print(\"train_input MAX: \", np.round(np.max(train_input, axis=(0,1)), 2))\n",
    "print(\"train_input MEAN: \", np.round(np.mean(train_input, axis=(0,1)), 2))\n",
    "print(\"train_input STD: \", np.round(np.std(train_input, axis=(0,1)), 2))\n",
    "print(\"val_input MIN: \", np.round(np.min(val_input, axis=(0,1)), 2))\n",
    "print(\"val_input MAX: \", np.round(np.max(val_input, axis=(0,1)), 2))\n",
    "print(\"val_input MEAN: \", np.round(np.mean(val_input, axis=(0,1)), 2))\n",
    "print(\"val_input STD: \", np.round(np.std(val_input, axis=(0,1)), 2))\n",
    "print(\"test_input MIN: \", np.round(np.min(test_input, axis=(0,1)), 2))\n",
    "print(\"test_input MAX: \", np.round(np.max(test_input, axis=(0,1)), 2))\n",
    "print(\"test_input MEAN: \", np.round(np.mean(test_input, axis=(0,1)), 2))\n",
    "print(\"test_input STD: \", np.round(np.std(test_input, axis=(0,1)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3987c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
