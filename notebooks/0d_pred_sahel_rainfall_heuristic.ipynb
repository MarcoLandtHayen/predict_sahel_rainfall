{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7dbe65-6dc0-41a5-aa96-d9a0653e54d6",
   "metadata": {},
   "source": [
    "### Simple heuristics to predict Sahel rainfall\n",
    "\n",
    "As simple baseline, we try **various heuristics**:\n",
    "\n",
    "- Use the value of the **previous month** as prediction for the current month. This works only for **lead time = 1**.\n",
    "- Use the value of the **previous year**'s same month as prediction for the current years current month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca00440-1fbe-473b-be11-d7cac0887060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from predict_sahel_rainfall.preprocessing import prepare_inputs_and_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7b72d",
   "metadata": {},
   "source": [
    "### Prepare inputs and targets\n",
    "\n",
    "Load collection of climate indices directly from GitHub release.\n",
    "Use the complete preprocessing pipeline function, although we only need the target series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff7d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set parameters:\n",
    "\n",
    "# Set url to csv file containing CICMoD indices from desired release:\n",
    "data_url = (\n",
    "    \"https://github.com/MarcoLandtHayen/climate_index_collection/\"\n",
    "    \"releases/download/v2023.03.29.1/climate_indices.csv\"\n",
    ")\n",
    "\n",
    "# Choose ESM ('CESM' or 'FOCI'):\n",
    "ESM = 'FOCI'\n",
    "\n",
    "# Select target index:\n",
    "target_index = 'PREC_SAHEL'\n",
    "\n",
    "# Select all input features:\n",
    "input_features = [\n",
    "    'AMO', 'ENSO_12', 'ENSO_3', 'ENSO_34', 'ENSO_4', 'NAO_PC', 'NAO_ST', \n",
    "    'NP', 'PDO_PC', 'PREC_SAHEL', 'SAM_PC', 'SAM_ZM', 'SAT_N_ALL', 'SAT_N_LAND',\n",
    "    'SAT_N_OCEAN', 'SAT_S_ALL', 'SAT_S_LAND', 'SAT_S_OCEAN', 'SOI',\n",
    "    'SSS_ENA', 'SSS_NA', 'SSS_SA', 'SSS_WNA', 'SST_ESIO', 'SST_HMDR',\n",
    "    'SST_MED', 'SST_TNA', 'SST_TSA', 'SST_WSIO'\n",
    "]\n",
    "\n",
    "# # Select subset of input features:\n",
    "# input_features = ['PREC_SAHEL', 'SAM_ZM']\n",
    "\n",
    "# Choose, whether to add months as one-hot encoded features:\n",
    "add_months = False\n",
    "\n",
    "# Choose, whether to normalize target index:\n",
    "norm_target = True\n",
    "\n",
    "# Set lead time for target index:\n",
    "lead_time = 1\n",
    "\n",
    "# Specify input length:\n",
    "input_length = 1\n",
    "\n",
    "# Specify amount of combined training and validation data relative to test data:\n",
    "train_test_split = 0.9\n",
    "\n",
    "# Specify relative amount of combined training and validation used for training:\n",
    "train_val_split = 0.8\n",
    "\n",
    "## Optionally choose to scale or normalize input features according to statistics from training data:\n",
    "# 'no': Keep raw input features.\n",
    "# 'scale_01': Scale input features with min/max scaling to [0,1].\n",
    "# 'scale_11': Scale input features with min/max scaling to [-1,1].\n",
    "# 'norm': Normalize input features, hence subtract mean and divide by std dev.\n",
    "scale_norm = 'norm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74fc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs and target:\n",
    "(\n",
    "    train_input,\n",
    "    train_target,\n",
    "    val_input,\n",
    "    val_target,\n",
    "    test_input,\n",
    "    test_target,\n",
    "    train_mean,\n",
    "    train_std,\n",
    "    train_min,\n",
    "    train_max,\n",
    ") = prepare_inputs_and_target(    \n",
    "    data_url=data_url,\n",
    "    ESM=ESM,\n",
    "    target_index=target_index,\n",
    "    input_features=input_features,\n",
    "    add_months=add_months,\n",
    "    norm_target=norm_target,\n",
    "    lead_time=lead_time,\n",
    "    input_length=input_length,\n",
    "    train_test_split=train_test_split,\n",
    "    train_val_split=train_val_split,\n",
    "    scale_norm=scale_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2068647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000416615970107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.concatenate([train_target, val_target, test_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd0bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0dc7681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input shape (samples, time steps, features):  (8639, 1, 29)\n",
      "val_input shape (samples, time steps, features):  (2160, 1, 29)\n",
      "test_input shape (samples, time steps, features):  (1200, 1, 29)\n",
      "\n",
      "train_target shape (samples, 1):  (8639, 1)\n",
      "val_target shape (samples, 1):  (2160, 1)\n",
      "test_target shape (samples, 1):  (1200, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions:\n",
    "print(\"train_input shape (samples, time steps, features): \", train_input.shape)\n",
    "print(\"val_input shape (samples, time steps, features): \", val_input.shape)\n",
    "print(\"test_input shape (samples, time steps, features): \", test_input.shape)\n",
    "\n",
    "print(\"\\ntrain_target shape (samples, 1): \", train_target.shape)\n",
    "print(\"val_target shape (samples, 1): \", val_target.shape)\n",
    "print(\"test_target shape (samples, 1): \", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30dfbd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse:  1.739\n",
      "test correl:  0.207\n"
     ]
    }
   ],
   "source": [
    "## Use the previous month as prediction for the current month. This works only for lead time=1.\n",
    "\n",
    "## CESM:\n",
    "\n",
    "# mse on test data:\n",
    "print('test mse: ', np.round(np.mean((test_target[1:,0]-test_target[:-1,0])**2),3))\n",
    "print('test correl: ', np.round(np.corrcoef(np.stack([test_target[1:,0],test_target[:-1,0]]))[0,1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca1ce1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse:  1.324\n",
      "test correl:  0.187\n"
     ]
    }
   ],
   "source": [
    "## Use the previous month as prediction for the current month. This works only for lead time=1.\n",
    "\n",
    "## FOCI:\n",
    "\n",
    "# mse on test data:\n",
    "print('test mse: ', np.round(np.mean((test_target[1:,0]-test_target[:-1,0])**2),3))\n",
    "print('test correl: ', np.round(np.corrcoef(np.stack([test_target[1:,0],test_target[:-1,0]]))[0,1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9bcff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse:  2.328\n",
      "test correl:  -0.058\n"
     ]
    }
   ],
   "source": [
    "## Use the value of the **previous year**'s same month as prediction for the current years current month.\n",
    "\n",
    "## CESM:\n",
    "\n",
    "# mse on test data:\n",
    "print('test mse: ', np.round(np.mean((test_target[12:,0]-test_target[:-12,0])**2),3))\n",
    "print('test correl: ', np.round(np.corrcoef(np.stack([test_target[12:,0],test_target[:-12,0]]))[0,1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bb9b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse:  1.47\n",
      "test correl:  0.089\n"
     ]
    }
   ],
   "source": [
    "## Use the value of the **previous year**'s same month as prediction for the current years current month.\n",
    "\n",
    "## FOCI:\n",
    "\n",
    "# mse on test data:\n",
    "print('test mse: ', np.round(np.mean((test_target[12:,0]-test_target[:-12,0])**2),3))\n",
    "print('test correl: ', np.round(np.corrcoef(np.stack([test_target[12:,0],test_target[:-12,0]]))[0,1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d7f58",
   "metadata": {},
   "source": [
    "### Discussion on using simple heuristics to predict Sahel rainfall\n",
    "\n",
    "Find the autocorrelation of Sahel precipitation index to be rather low. For a time shift of only **one months**, the correlation drops to 0.207 and 0.187 for CESM and FOCI test data, respectively. Further increasing the time shift to **one year**, correlation reads -0.058 and 0.089 for CESM and FOCI test data, respectively.\n",
    "\n",
    "The observed mse is way higher, compared to former experiments with simple CNN/fc models and linear regression. We therefore find the approach to use simple heuristics as predictor to be useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8d4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
